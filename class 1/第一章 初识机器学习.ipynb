{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一节 初识机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 课程大纲\n",
    "![](./material/机器学习课程大纲.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2机器学习基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1人工智能，机器学习，深度学习\n",
    "#### 关系图\n",
    "![](./material/人工智能-机器学习-深度学习关系图.png)\n",
    "#### 人工智能\n",
    "人工智能（Artificial Intelligence）：为机器赋予人的能力\n",
    "* 强人工智能：复杂的、拥有与人类智慧同样特性的机器；像星球大战中的C-3PO；邪恶的，如终结者；我们目前还无法实现。\n",
    "* 弱人工智能：能够与人一样，甚至比人更好地执行特定任务的技术；如图像分类，人脸识别，AlphaGo。\n",
    "\n",
    "#### 机器学习\n",
    "机器学习（Machine Learning）：一种实现人工智能的方法\n",
    "* 机器学习即机器自己来学习，最基本的做法，是使用算法来解析数据、从中学习，然后对真实世界中的事件做出决策和预测。与传统的为解决特定任务、硬编码的软件程序不同，机器学习是用大量的数据来“训练”，通过各种算法从数据中学习如何完成任务，如商品推荐，销量预测等。\n",
    "* 传统的机器学习算法在指纹识别、人脸检测、物体检测等领域的应用基本达到了商业化的要求或者特定场景的商业化水平，但每前进一步都异常艰难，直到深度学习算法的出现。\n",
    "\n",
    "#### 深度学习\n",
    "深度学习（Deep Learning）：一种是实现机器学习的技术\n",
    "* 深度学习本来并不是一种独立的学习方法，只是模拟人脑神经元产生的，早期机器学习的算法的一种；由于近几年该领域发展迅猛，一些特有的学习手段相继被提出（如残差网络），在语言、图像领域等众多领域达到了普通机器学习算法难以达到的高度，因此越来越多的人将其单独看作一种学习的方法。\n",
    "* 深度学习摧枯拉朽般地实现了各种任务，使得似乎所有的机器辅助功能都变为可能。无人驾驶汽车，预防性医疗保健，甚至是更好的电影推荐，都近在眼前，或者即将实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 机器学习解决哪些问题\n",
    "* 分类问题；狗猫图片识别、垃圾邮件过滤、文本情感分析\n",
    "* 回归问题：销量预测、点击率预测、流量预测\n",
    "* 聚类问题：用户分级、基于用户位置信息的商业选址\n",
    "* 推荐&关联：音乐推荐、啤酒尿布\n",
    "![](./material/机器学习应用.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 最简单的机器学习模型：线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们通过一个线性回归模型的例子，来感知下机器学习的模型是一个什么东西，又是如何被训练出来的。\n",
    "\n",
    "大自然有这样的规则，相比凉爽的天气，蟋蟀在较为炎热的天气里鸣叫更为频繁。\n",
    "现在我们就用该数据集训练一个模型，来学习温度与鸣叫次数之间的关系。\n",
    "\n",
    "最终目的是：我告诉你蟋蟀每分钟叫了多少次，你要告诉我现在大概是多少摄氏度。\n",
    "### 每分钟虫鸣与温度关系图\n",
    "<img src=\"./material/温度与虫鸣1.png\" width=\"500px\" height=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此曲线图表明温度随着鸣叫声次数的增加而上升。鸣叫声与温度之间的关系是线性关系，因此我们可以绘制一条直线来近似地表示这种关系\n",
    "<img src=\"./material/温度与虫鸣2.png\" width=\"500px\" height=\"500px\">\n",
    "\n",
    "画出这条直线之后，只要你给我每分钟虫鸣声的次数，我就能读出来大致的温度是多少。那么其实，这条线我们就可以理解为是一个温度预测模型，输入数据x为每分钟虫鸣声，输出y就是通过这条直线读出的温度，就是模型的预测值。\n",
    "同样，在数学上，我们可以用一个公式来代表这条直线：\n",
    "$$y = wx+b$$\n",
    "那我们现在的任务就是找到这条直线的$w$和$b$，那机器又是如何找到的呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此之前我们先假设有以下两种情况：\n",
    "<img src=\"./material/损失.png\" width=\"500px\" height=\"500px\">\n",
    "\n",
    "这两条直线，明显左边的偏差更多，更加不准确；而右边的就要准确很多了，更能表示温度与虫鸣之间的关系；而这种准确不准确的程度，我们使用一个词来表示就是**损失**。那我们现在的目的，就是找到一组($w$, $b$)，使这个损失最小就是最优模型。\n",
    "同样，我们用一个数学公式来表示损失的大小就是：$$MSE = \\frac{1}{N} \\sum_{(x,y)\\in D} (y - prediction(x))^2$$\n",
    "这个$MSE$被称作均方误差，指的是每个样本的平均平方损失。\n",
    "那现在对我们来说，就是就是找到一组($w$, $b$)，保证$MSE$尽可能的小，就是我们最想要的最优模型了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那接下来的事情就很好理解了，机器最擅长的就是计算了，它会不停尝试不同的($w$, $b$)组合，每尝试一次，计算一次$MSE$，直到找到最小的损失，此时的($w$, $b$)参数组合，就是我们训练好的模型了，而机器不停尝试寻找最优的这个过程就被称作**训练**。\n",
    "<img src=\"./material/训练试错.svg\" width=\"700px\" height=\"700px\">\n",
    "\n",
    "当然机器肯定不是胡乱尝试的，我们会有很多算法去尽可能减少尝试的次数，降低计算的复杂度，最常用的就是*梯度下降算法*，这个之后再说。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 鸢尾花分类\n",
    "### 1.4.1 建模流程介绍\n",
    "### 业务理解 -> 获取数据 -> 数据清洗 -> 特征工程 -> 建立模型 -> 交叉验证 -> 上线部署\n",
    "![](./material/机器学习流程图.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 鸢尾花分类\n",
    "### 鸢尾花数据集\n",
    "Iris也称鸢尾花卉数据集，是一类多重变量分析的数据集。通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个属性预测鸢尾花卉属于（Setosa，Versicolour，Virginica）三个种类中的哪一类。而在python的sklearn库中有内置这个数据集，我们就先拿这个数据集来做为机器学习的第一站。\n",
    "![](./material/鸢尾花.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入所需模块\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris  # 鸢尾花数据集\n",
    "from sklearn.linear_model import LogisticRegression  # 逻辑回归分类模型\n",
    "from sklearn.model_selection import train_test_split  # 用于训练集和测试集分割的方法\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'C:\\\\my program\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()  # 载入鸢尾花数据集\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "5                  5.4               3.9                1.7               0.4   \n",
       "6                  4.6               3.4                1.4               0.3   \n",
       "7                  5.0               3.4                1.5               0.2   \n",
       "8                  4.4               2.9                1.4               0.2   \n",
       "9                  4.9               3.1                1.5               0.1   \n",
       "10                 5.4               3.7                1.5               0.2   \n",
       "11                 4.8               3.4                1.6               0.2   \n",
       "12                 4.8               3.0                1.4               0.1   \n",
       "13                 4.3               3.0                1.1               0.1   \n",
       "14                 5.8               4.0                1.2               0.2   \n",
       "15                 5.7               4.4                1.5               0.4   \n",
       "16                 5.4               3.9                1.3               0.4   \n",
       "17                 5.1               3.5                1.4               0.3   \n",
       "18                 5.7               3.8                1.7               0.3   \n",
       "19                 5.1               3.8                1.5               0.3   \n",
       "20                 5.4               3.4                1.7               0.2   \n",
       "21                 5.1               3.7                1.5               0.4   \n",
       "22                 4.6               3.6                1.0               0.2   \n",
       "23                 5.1               3.3                1.7               0.5   \n",
       "24                 4.8               3.4                1.9               0.2   \n",
       "25                 5.0               3.0                1.6               0.2   \n",
       "26                 5.0               3.4                1.6               0.4   \n",
       "27                 5.2               3.5                1.5               0.2   \n",
       "28                 5.2               3.4                1.4               0.2   \n",
       "29                 4.7               3.2                1.6               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "120                6.9               3.2                5.7               2.3   \n",
       "121                5.6               2.8                4.9               2.0   \n",
       "122                7.7               2.8                6.7               2.0   \n",
       "123                6.3               2.7                4.9               1.8   \n",
       "124                6.7               3.3                5.7               2.1   \n",
       "125                7.2               3.2                6.0               1.8   \n",
       "126                6.2               2.8                4.8               1.8   \n",
       "127                6.1               3.0                4.9               1.8   \n",
       "128                6.4               2.8                5.6               2.1   \n",
       "129                7.2               3.0                5.8               1.6   \n",
       "130                7.4               2.8                6.1               1.9   \n",
       "131                7.9               3.8                6.4               2.0   \n",
       "132                6.4               2.8                5.6               2.2   \n",
       "133                6.3               2.8                5.1               1.5   \n",
       "134                6.1               2.6                5.6               1.4   \n",
       "135                7.7               3.0                6.1               2.3   \n",
       "136                6.3               3.4                5.6               2.4   \n",
       "137                6.4               3.1                5.5               1.8   \n",
       "138                6.0               3.0                4.8               1.8   \n",
       "139                6.9               3.1                5.4               2.1   \n",
       "140                6.7               3.1                5.6               2.4   \n",
       "141                6.9               3.1                5.1               2.3   \n",
       "142                5.8               2.7                5.1               1.9   \n",
       "143                6.8               3.2                5.9               2.3   \n",
       "144                6.7               3.3                5.7               2.5   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "5         0  \n",
       "6         0  \n",
       "7         0  \n",
       "8         0  \n",
       "9         0  \n",
       "10        0  \n",
       "11        0  \n",
       "12        0  \n",
       "13        0  \n",
       "14        0  \n",
       "15        0  \n",
       "16        0  \n",
       "17        0  \n",
       "18        0  \n",
       "19        0  \n",
       "20        0  \n",
       "21        0  \n",
       "22        0  \n",
       "23        0  \n",
       "24        0  \n",
       "25        0  \n",
       "26        0  \n",
       "27        0  \n",
       "28        0  \n",
       "29        0  \n",
       "..      ...  \n",
       "120       2  \n",
       "121       2  \n",
       "122       2  \n",
       "123       2  \n",
       "124       2  \n",
       "125       2  \n",
       "126       2  \n",
       "127       2  \n",
       "128       2  \n",
       "129       2  \n",
       "130       2  \n",
       "131       2  \n",
       "132       2  \n",
       "133       2  \n",
       "134       2  \n",
       "135       2  \n",
       "136       2  \n",
       "137       2  \n",
       "138       2  \n",
       "139       2  \n",
       "140       2  \n",
       "141       2  \n",
       "142       2  \n",
       "143       2  \n",
       "144       2  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}  # 列个字典做备注，target的各个值代表不同的鸢尾花种类\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "iris_df = pd.DataFrame(X, columns=iris['feature_names'])  # 为了更方便理解，将array数组数据合并成DataFrame\n",
    "iris_df['target'] = y  # 也把目标标签加进去\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据特征：\n",
      "      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "60                 5.0               2.0                3.5               1.0\n",
      "116                6.5               3.0                5.5               1.8\n",
      "144                6.7               3.3                5.7               2.5\n",
      "119                6.0               2.2                5.0               1.5\n",
      "108                6.7               2.5                5.8               1.8 \n",
      "\n",
      "训练数据标签：\n",
      " 60     1\n",
      "116    2\n",
      "144    2\n",
      "119    2\n",
      "108    2\n",
      "Name: target, dtype: int32\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "# 直接将数据按7：3分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_df.iloc[:, :-1], iris_df['target'], test_size=0.3, random_state=0)\n",
    "print('训练数据特征：\\n', X_train.head(), '\\n')\n",
    "print('训练数据标签：\\n', y_train.head())\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练\n",
      "模型训练完成\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "model = LogisticRegression()  # 调用逻辑回归模型，直接使用默认参数\n",
    "print('开始训练')\n",
    "model.fit(X_train, y_train)  # 用训练数据对模型进行训练\n",
    "print('模型训练完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "114                5.8               2.8                5.1               2.4\n",
      "62                 6.0               2.2                4.0               1.0\n",
      "33                 5.5               4.2                1.4               0.2\n",
      "107                7.3               2.9                6.3               1.8\n",
      "7                  5.0               3.4                1.5               0.2\n"
     ]
    }
   ],
   "source": [
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>prediction</th>\n",
       "      <th>equal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     real  prediction  equal\n",
       "114     2           2   True\n",
       "62      1           1   True\n",
       "33      0           0   True\n",
       "107     2           2   True\n",
       "7       0           0   True\n",
       "100     2           2   True\n",
       "40      0           0   True\n",
       "86      1           1   True\n",
       "76      1           1   True\n",
       "71      1           1   True\n",
       "134     2           2   True\n",
       "51      1           1   True\n",
       "73      1           1   True\n",
       "54      1           1   True\n",
       "63      1           1   True\n",
       "37      0           0   True\n",
       "78      1           2  False\n",
       "90      1           1   True\n",
       "45      0           0   True\n",
       "16      0           0   True\n",
       "121     2           2   True\n",
       "66      1           2  False\n",
       "24      0           0   True\n",
       "8       0           0   True\n",
       "126     2           2   True\n",
       "22      0           0   True\n",
       "44      0           0   True\n",
       "97      1           1   True\n",
       "93      1           1   True\n",
       "26      0           0   True\n",
       "137     2           2   True\n",
       "84      1           2  False\n",
       "27      0           0   True\n",
       "127     2           2   True\n",
       "132     2           2   True\n",
       "59      1           2  False\n",
       "18      0           0   True\n",
       "83      1           2  False\n",
       "61      1           1   True\n",
       "92      1           1   True\n",
       "112     2           2   True\n",
       "2       0           0   True\n",
       "141     2           2   True\n",
       "43      0           0   True\n",
       "10      0           0   True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测结果\n",
    "pre = model.predict(X_test)  # 使用训练好的模型对训练集的数据进行预测\n",
    "result = pd.DataFrame({'real': y_test, 'prediction': pre})  # 将实际结果与预测结果放在同一个表中来对比观察\n",
    "result['equal'] = result['real'] == result['prediction']  # 预测值与实际结果相同？\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "num_test = len(result)\n",
    "num_true = sum(result['equal'])\n",
    "print('准确率：', num_true/num_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 术语"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 基本术语\n",
    "#### 标签\n",
    "标签是我们要预测的事物，即简单线性回归中的 y 变量，鸢尾花分类中即是我们要预测的三种花的种类。\n",
    "\n",
    "#### 特征\n",
    "特征是输入变量，即简单线性回归中的 x 变量，鸢尾花分类中即是花萼长度，花萼宽度，花瓣长度，花瓣宽度4个属性。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目可能会使用数百万个特征。\n",
    "在垃圾邮件检测器示例中，特征可能包括\n",
    "* 电子邮件文本中的字词\n",
    "* 发件人的地址\n",
    "* 发送电子邮件的时段\n",
    "* 电子邮件中包含“一种奇怪的把戏”这样的短语\n",
    "\n",
    "#### 样本\n",
    "样本是指数据的特定实例，可以理解为训练数据中的一条记录，鸢尾花中一行记录就是一个样本。我们将样本分为以下两类：\n",
    "* 有标签样本\n",
    "* 无标签样本\n",
    "\n",
    "有标签样本同时包含特征和标签;无标签样本包含特征，但不包含标签。\n",
    "\n",
    "#### 模型\n",
    "模型定义了特征与标签之间的关系。例如，鸢尾花分类中将花萼长度，花萼宽度，花瓣长度，花瓣宽度4个属性与“鸢尾花种类”联系起来，垃圾邮件检测模型可能会将某些特征与“垃圾邮件”紧密联系起来。\n",
    "模型的生命周期有两个阶段：\n",
    "* **训练**是指创建或学习模型。也就是说，向模型展示有标签样本，让模型逐渐学习特征与标签之间的关系。\n",
    "* **预测**是指将训练后的模型应用于无标签样本。也就是说，使用经过训练的模型做出有用的预测 (y')。\n",
    "\n",
    "#### 分类与回归\n",
    "回归模型可预测连续值。例如，回归模型做出的预测可回答如下问题：\n",
    "* 加利福尼亚州一栋房产的价值是多少？\n",
    "* 用户点击此广告的概率是多少？\n",
    "\n",
    "分类模型可预测离散值。例如，分类模型做出的预测可回答如下问题：\n",
    "* 某个指定电子邮件是垃圾邮件还是非垃圾邮件？\n",
    "* 这是一张狗、猫还是仓鼠图片？\n",
    "\n",
    "#### 监督学习与非监督学习\n",
    "* 监督式学习：有输入数据，有标签；如回归、分类算法。\n",
    "* 非监督式学习：只有输入数据，无标签；如聚类、关联规则算法。\n",
    "* 半监督式学习：有输入数据，但部分数据是有标签的，部分没有标签，是一种监督式和非监督式学习的手段都可以使用的学习方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 工具介绍\n",
    "### 1.6.1语言\n",
    "#### python\n",
    "Python 是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言。也是目前最适合用作机器学习的语言。\n",
    "\n",
    "python官网：https://www.python.org/\n",
    "\n",
    "廖雪峰的python教程：https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000\n",
    "\n",
    "### IDE\n",
    "#### Jupyter\n",
    "\n",
    "#### Pycharm\n",
    "![](./material/pycharm界面.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.2第三方库\n",
    "#### numpy\n",
    "numpy是支持 Python语言的数值计算扩充库，其拥有强大的高维度数组处理与矩阵运算能力。除此之外，numpy还内建了大量的函数，方便你快速构建数学模型。\n",
    "\n",
    "#### 安装numpy\n",
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg: 2.5\n",
      "std: 1.118033988749895\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # 导入模块\n",
    "\n",
    "test = [1, 2, 3, 4]  # 创建一个列表\n",
    "avg = np.mean(test)  # 计算平均值\n",
    "std = np.std(test)  # 计算方差\n",
    "print('avg:', avg)  # 打印结果\n",
    "print('std:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr1:\n",
      " [[1 2 3]\n",
      " [2 3 4]\n",
      " [4 5 6]] \n",
      "\n",
      "shape of arr2: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([[1, 2, 3],\n",
    "               [2, 3, 4],\n",
    "               [4, 5, 6]])  # 创建一个array数组\n",
    "arr2 = np.array([[1, 1, 1],\n",
    "               [2, 2, 3],\n",
    "               [3, 3, 3]])\n",
    "print('arr1:\\n', arr1, '\\n')\n",
    "print('shape of arr2:', arr2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add:\n",
      " [[2 3 4]\n",
      " [4 5 7]\n",
      " [7 8 9]] \n",
      "\n",
      "reduce:\n",
      " [[0 1 2]\n",
      " [0 1 1]\n",
      " [1 2 3]] \n",
      "\n",
      "divide:\n",
      " [[1.         2.         3.        ]\n",
      " [1.         1.5        1.33333333]\n",
      " [1.33333333 1.66666667 2.        ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_add = arr1 + arr2  # 两个数据相加\n",
    "arr_reduce = arr1 - arr2  # 两个数组相减\n",
    "arr_divide = arr1 / arr2  # 两个数组相乘\n",
    "print('add:\\n', arr_add, '\\n')\n",
    "print('reduce:\\n', arr_reduce, '\\n')\n",
    "print('divide:\\n', arr_divide, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas\n",
    "pandas 是基于NumPy 的一种工具，该工具是为了解决数据分析任务而创建的。Pandas 纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具。pandas提供了大量能使我们快速便捷地处理数据的函数和方法。\n",
    "\n",
    "#### pandas安装\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b     c\n",
       "0  1  5   9.0\n",
       "1  2  6  10.0\n",
       "2  3  7  11.0\n",
       "3  4  8   NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [1, 2, 3, 4], 'b': [5, 6, 7, 8], 'c': [9, 10, 11, np.nan]})  # 创建一个DataFrame\n",
    "print('shape:', df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>999.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b      c   d\n",
       "0  1  5    9.0   6\n",
       "1  2  6   10.0   8\n",
       "2  3  7   11.0  10\n",
       "3  4  8  999.0  12"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['d'] = df['a'] + df['b']  # d列的值等于a列加b列\n",
    "df.fillna(999, inplace=True)  # 将空值填充为999\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### matplotlib\n",
    "Matplotlib 是一个 Python 的 2D绘图库，它以各种硬拷贝格式和跨平台的交互式环境生成出版质量级别的图形。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztvXm4JGd13/89VdXLXWeXNFpG0iBZSMIglAlSDAYjCSyQbYHjEENI9MPwk4MhNo7zGAUebCAmEXFw8uNnHogctrCZzQpCiN0IWSwykiykESNZGi1oRqPZZ+7a3bWc/PG+b9Vb1VW93Nvb7Xs+zzPP3O6urnq7bt9Tp77v95yXmBmCIAjC2scZ9gAEQRCE3iABXRAEYUyQgC4IgjAmSEAXBEEYEySgC4IgjAkS0AVBEMYECegdQERPENFVBa/9MhE9POgxrRYiOoeImIi8YY9FGB72d5uI3kFE/2vYY1otRPRuIvr0sMcxDOSPeZUw898BuKDddkT0bgDnMfPr+z4oQVgBzPyfhz0GYXVIhr5GkcxaGFeIyB32GNYqEtA75xIiup+IThLR54moCgBE9CtEtM9sRERvJ6L9RDRPRA8T0ZVEdDWAdwD4l0S0QEQ/zTsAEV1KRP+g3/tFfZw/s4+j9/8MgI8T0SYiupWIDhPRcf3zmdb+biei/0JEf6/H/RUi2pw57L8iop8T0REiemevT5qwdrClCkuSuy7v+0FEDhHdQER7iegoEX0h57tl7/uPiegAET1NRG/S+z5Pv/YJIvowEd1GRIsAXkpE1+i/hTkiekrf4Zp9mbFdr/d3gIj+KHPIMhH9b/239CAR7erpyRpRJKB3zmsAXA3gXADPBfD/ZDcgogsAvBXAP2XmGQC/CuAJZv4GgP8M4PPMPM3Mz8t5bxnAzQA+AWAzgM8BeHVms9P0a2cDuB7q9/dx/XgHgGUAf5l5z78B8DsATgcQAPhg5vUXQUlGVwL4EyK6sPVpENYZRd+P3wfwKgAvgfpuHQfwobwd6ITm3wO4CsB5+j1ZXgfgfQBmANwJYBHqu7sRwDUA3kxEr8q856UAzgfwcgA3ZOa5fgPAX+v334Lmv4uxRAJ653yQmZ9m5mMAvgrgkpxtQgAVABcRUYmZn2DmvR3u/3KoOY0PMrPPzH8D4O8z20QA/pSZ68y8zMxHmfnLzLzEzPNQfxDZP5ZPMfNuZl4E8C4Ar8nc0r5H7+unAH4KoOliI6xrir4fvwvgncy8j5nrAN4N4LcKpMDXAPg4Mz/IzEsA3pOzzVeY+QfMHDFzjZlvZ+YH9OP7oRKc7Hf7Pcy8yMwPQCU2r7Veu5OZb2PmEMCnsE6+1xLQO+cZ6+clANPZDZj5UQBvg/pyHyKivyai0zvc/+kA9nO6W9pTmW0OM3PNPCCiSSL6n0T0JBHNAbgDwMZMwLb38SSAEoCt3XwuYV1T9P04G8DNRHSCiE4A2AOV0Jyas4/Tkf4eZr/XTc8R0WVE9D0tJ54E8G+R/t5m3/OkPk7RuKvrYd5JAnqPYebPMvOLoL7wDOD95qU2bz0A4AwiIuu5s7K7zzz+I6jb4cuYeRbAi/XzRfvYAcAHcKTNWAShHU8BeAUzb7T+VZl5f862BwCcaT3Ofq+B5u/2Z6GkkrOYeQOAjyD9vc7uZweAp7v6BGOIBPQeQkQXENEVRFQBUIPStEP98kEA5xBR0Tn/kd72rUTkEdG1AF7Q5pAz+hgn9ITUn+Zs83oiuoiIJgG8F8CX9G2oIKyGjwB4HxGdDQBEtE1/Z/P4AoA3ENGF+nv4Jx3sfwbAMWauEdELoDT2LO/Sd6kXA3gDgM93/zHGCwnovaUC4EaoDPgZAKdAuVsA4Iv6/6NEdG/2jczcAPCbAN4I4ASA1wO4FUC9xfH+B4AJfbwfA/hGzjafgppofQZAFWoySxBWy/8HlUF/i4jmob5/l+VtyMxfh5qM/x6AR6GSF6D1d/v3ALxX7/tPoC4KWb6v9/ddAP+Nmb+1gs8xVpAscDG6ENFdAD7CzB9f4ftvB/BpZl7z1X/C+KCdMrsBVJg5WMH7zwHwOIDSSt4/zkiGPkIQ0UuI6DQtuVwHZY/My7oFYU1BRK8mojIRbYKaV/qqBOPeIwF9tLgAyhp2EmrC87eY+cBwhyQIPeF3ARwGsBdqrujNwx3OeCKSiyAIwpjQNkMnorO0H3SPLqH9A/38u0mVuN+n/72y/8MVBEEQimiboRPRdgDbmfleIpoBcA9Uye9rACww83/r9GBbt27lc845ZxXDFYRi7rnnniPMvG0Yx5bvttBPOv1ut62c0hruAf3zPBHtAXDGSgZ1zjnn4O67717JWwWhLUT05LCOLd9toZ90+t3ualJU24WeD+Au/dRbSXUg/Jievc57z/VEdDcR3X348OFuDicIQ6FIZhSEUafjgE5E0wC+DOBtzDwH4MMAngXVpOoAgA/kvY+Zb2LmXcy8a9u2odwNC0K3BAD+iJkvhGqa9hYiumjIYxKEtnQU0ImoBBXMP6O7AIKZDzJzyMwRgL9C+zJ1QVgTMPMBZr5X/zwP1XhqRTKjIAySTlwuBOCjAPYw819Yz2+3Nns1VOWXIIwVOTKjIIwsnbSTfCGAfw3gASK6Tz/3DgCvJaJLoLqkPQFVOCAIY0OOzJh9/XqohUawY8eOAY9OEJrpxOVyJ5rbVgLAbb0fjiCMBnkyYxZmvgnATQCwa9cuqdATho6U/gtChiKZURBGHQnogtCMkRmvkErotUkYMb7wk6cQhNGwhzJQxn5JJkHolhYyo7BG+IefH8cff/l+nLlpAr90XnbluvFFAvoYcs4NX1vR+5648Zoej0QoYqkR4MO378W/u+J8lD25Ue41jUBl5rVgfS3OJd8kQRgCdz1+DP//3z6KB/afGPZQxpJIT1GbwL5ekIAuCEMgDFXECUIxx/SDUDcdrEtAFwSh35iAE0YS0PtBpM+rv84umBLQBWEImIATSEDvC+ZCKZKLIAh9xwRyydD7g7kDasikqCAI/SZiydD7yahILt//x8O49f6nB3Y8sS0KwhAwk6FhtL4kgUERZ+hDLiz66J2P48h8Hb/23NMHcjzJ0AVhCISSofcVI2UN2+VSa4TwB3hRkYAuCEMgFA29r0Q8GpOiy3440Iu2BHRBGAIS0PuLUbIGmR3nseyHA72oSEAXhCEgk6L9JRyVDL0RIhjgPIlMigrCEEgmRSWg94NoRHzoNT/EIH/DEtAFYQhIht5fTIY+bMml5odwnME17hTJRRCGQFxYtM76dQ8Kk6HXh3h+mRnLvrhcBGHsCaX0v6+MQul/I4wQ8WCLmySgC8IQiMTl0ldMDB2m5FJrqGOHEce/734jAV0QhkAgGXpfGYVJ0WU/6SPjD8jpIgFdEIZAJO1z+8oo2BbtgD6ovvcS0AVhCEiG3l+iEXC5LDesDH1A45CALghDINHQxeXSD6IR6OWSklwkQxeE8UUy9ARmxm0PHEDQwyzW7GqY3RZrvmTogrAuMNr5oNwPo8zPDszh9z5zL76++5me7XMUCotsyUU0dEEYY6RSNGGhFgAAHnx6rmf7HDWXy6DuFCSgC8IQkCXoEozO/dAzvQvoI+dyEduiIIwvskh0gtGa9xzofYY+zCXo6raGHojkIghjS9LLRQK6ydAPztVxbLHRk32OQum/SC6CsE6QDD3Bthb2Snax1xRlHs45Xm4kn6uXDp5WSEAXhCEQiA89xrb37Tkw35N92jF8WLKL+NAFYZ0gi0QnmAx9ouT2TEe3J5uH5UWvSS8XQVgfjHO3xU/+8Al84e6nOt6+HqjAd/aWSRyer/dkDKGVog9LR0+V/g9oDG0DOhGdRUTfI6I9RPQgEf2Bfn4zEX2biB7R/2/q/3AFYTwY50rRL97zFG657+mOt6/5KthtmCilZIrVYBdsDau4KG1bHB3JJQDwR8x8IYDLAbyFiC4CcAOA7zLz+QC+qx8LgtAB45yh1/yoK991PQhR8RxMlN2UTLEaUpLLsDJ0P0TZUyF2ZEr/mfkAM9+rf54HsAfAGQCuBfBJvdknAbyqX4MUhHFjnDP05UbY1YWq7kcqoJfclEyxGmzJZVgNump+iNlqCcCITooS0TkAng/gLgCnMvMBQAV9AKcUvOd6IrqbiO4+fPjw6kYrCGNC0g99/Fwu9SDs6kJVD0JUSi4mSi5qQe8ll2Fq6LNVD8AIZegGIpoG8GUAb2PmjqeimfkmZt7FzLu2bdu2kjEKwkAhoo8R0SEi2t2vY4RjLrl003Ss7keolhxUy27Ku90pjx6ax9MnllPPhSnb4vAkl5kJk6GPUEAnohJUMP8MM/+NfvogEW3Xr28HcKg/QxSEgfMJAFf38wDj3Mtl2e8uQ68FISqeztBXoKH//ufuw41ffyj1XDQCtsVl387QR0RyISIC8FEAe5j5L6yXbgFwnf75OgBf6f3wBGHwMPMdAI718xjjWinqhxHCiLvW0KslraH7YdeVnceXGji57Keei0bAtlhr2Br66GToLwTwrwFcQUT36X+vBHAjgJcR0SMAXqYfC8K6YTXzQ+OaoZsMuzsNPVIZetlFGHHX2exiPWiyO45EYVEQYXZCZeiDKv332m3AzHcCoIKXr+ztcARh7cDMNwG4CQB27dpVGIVuf/gQTttQxbNPm42fi/uhj1lzLhNYu7lQ1XxlW6yW3Hgfxu7XDmbGUiNskmpGIUNfboSYrqgQ2xgVyUUQhNXxjr95AB+5fW/qORPIxy1Dr+sioe586BGqJRfVkgpH3ejojTBCEHGT3TGMON7fMAI6M2PZDzFR9lBySZpzCcK4cGLZx7xelceQrFg0XrZFE4y7aQscFxbpDL2bgL5UV9s2SS6MeH/DcLnY/Wk8xxkpDV0Q1hVE9DkAPwJwARHtI6I3rnRfQRhhqRFioZ4O6GvNtvierz6IOx850na7WpyhdyO5RKmA3k35/2Ij0PvISC4Rx/sbRoZu7hgmSg5KLg3M5dJWQxeGxzk3fG3YQ1iXMPNre7Uvk5kv5UgCwNpxuXzqR0/CJcKLzt/acruVaOj1IFSSS1kH9C6qRc15zZdcdEDvc3a83AgRRBFmtKMFSM5DteSi5LbP0L90zz7s2DyJF5y7eVVjkQxdEPrIXE3Z6RazGTqvnQzd1zp1JxeflbtcVpih6/OatTuGbAX0Pmfo777lQbz50/emnqt1GdDf97Wf4as/7byhWRES0AWhj5gMPSu5mEnRtZCh17rIurvZ1n5PVZf+2/voBJOhR5zOxJkZE+XBZOiH5ms4NF9LPWc09IrnwHOprZspjBiuU2Qm7BwJ6ILQR+Z0wUtWconWUIa+3EXWnWzbWRBl5iRDjyWX5vd+Y/cB/Gjv0abn7TufmvW+MGJUvMG4XPLuXuwMvew6bS8qEQMOSUAXhJEmllwaQVoSMBr6kIpeusFYETtpJJZsm3zWfzw4j9seOJC7vVrzE3FzLiBfcvkf33kEH/vB403P2xdK+30hA57rwHWo7w6TMOKmDNxMDldKDkqu01GG7rkS0AVhpJnTkgtzOviYgLcGEvSuMnTTLdHe9uM/eALv+j/5fc5saaKifeN5Ad0Po9yLn3G5ZN8XRQyXoLLjAWTo2Tstcx6qJRee2/6iEkYsGbogjDpzVo8RWx4I15AP3ThIOpGHzLbMSb+ahXpQKDnU40w2ydDrOQE9LJiUNT50+9hme9chlL3+B3Q1tvQx4s/lqQzdb3PuQma4PYjGEtAFoY/MWQVFi3bAWUOVot04V4zUACQXraV6UPg5zb5Tpf85tsWQm2UNoEWGzirjLblO38vugxzJpR7YLhdqu6ZoGDHcHmTo4kPvgpX6wp+48Zoej0RYK8zX2mXoox/Ql7uo/rQXqAgjRslVQbfocxrJxdj7Si7lSi5h2JwFA2kZy3bHmAy9MpAMPWo5KdrOtmjuZBxxuQjCaDO3nARx27poAoAtTYwq3VR/2tm12X6xHhZO/ppM1jhSqrqFbpagoAujfZFMSS7McIzk0udJ0SDM0dD1Oat6Drw2dwnm4t6LDF0CuiD0kbmCDN0O4qOepSfe8g5cLkGzrLTYCBAVXLjiwKfllqJFLop6rBe5XCItYbgO9f2CqS42GQ3dXKhKLsptmnOZz+WKy0UQRpv5mo8tU2UAGQ2dOW4RO+o6+ko1dCORmInLvPdnM/SJcv5C0SE3B01AXSRndIvatIYOuA7Bof6f37yLTSpDb9OcKw7okqELwmgztxzgtA1VAEmGHkWsvNfa1jDqTpdu+rNkdWwg+dx577dtiwDiVYuyhDmyBqAy9C3T5dxjE6linajLFZC6JdAaul1nUPNDeA7Bcx2UPKdlc65YchENXRBGm7maj+06oB+er2PXn30H33zwGQCIfdf9ziC/87OD+HpBYU8ndKWh+2kNnZljJ0rehatuTR4CSqKws3x7X3nHX2wE2DJdUcdupF0uLtFAAnqeY6nmR/FnKrUpboonRcXlIgijzXwtydD3HJjDkYU69h5eAKCKXoD+a+gf/+HjWKyHeMUvbl/R+1eTodeDKC6eyrMdNmfoTn6GnuP1BpScs2PLZGqcZnvX0Rp6nxUt8/sLIoanYnjc4x1AW5dLLLlIhi4Io0sUMeZrPjZNllEtOXj44DyAZCKvlxr68cUGjizUc18LcybtuqG+Yg2dc5096e2TyUOgxaRoCx/6TNVD2XOafegD1NCB9OdLZehe6+ZcIrkIwhrAuDtmqyVMVzw8cWQRQHNA70WG/q6v7MYffv6+3Nfyeo10w3IXLpd0hh6lKjlbaejVFpOizFy4ePRSI8RU2VMXgmylKBEcZxAaupZcrPHVgjCW1DyntXVSMnRBWAOY1rkzVQ9TFS++9TcBq6Lvz7tZrq2IY4sNHF1o5L4WRgx/FROvZrydXBRqfpiSkuxKzry7BLv0H8j3oSerO+W7XCYrrs7s090WlctlABp6nKEnx6/7Iar691v2WjfnEpeLIKwBjAd9dqKEyXIyXbXkZySXHgScoKCSUu0/P5hyh8etBc0dFAu39SNMVdx4TKnq2FaSi+VyyUousUadCYpBGKEeRCpDL7tNtkWHCC4R+m0iMufWvtNSC1+bDL3dpKj6XypFBWGEMVWiSnJx4+dNxmsy2U6kjHY0wqjQGhflSC4H52q45L3fxo8fa+4xnqWr5lx+iCntCw8jTnnvc10uQQTXUT1XAG1bLOgdn5WmzIVxsuw2ZfYqQweIenPBbEW+hh7Gd2Al12myNabeH2voqx+LBHRB6BNlz8E/OXsTts1U4iAHAMu+CvRGY+2Fhu6HUWHPkjz9+XsPHcLJZR+Pa12/FfWclrhF1PwQ0/qzBhFjqc2kqO0GARBn2nbwC3IkDSApWJqqeJgoOanM3kyKug51fCeyEpjZuoNIxqcmRY3LRWXeRRfcRENffTgW26Ig9IlLztqIL7/5lwAgFdCXMhn6aiYsDX4YFd7W57lc/u7RIwA6W5C50ww90jZFO0NPuVxyPqftBgGUhh6xCn5lTwVCM8fghyrLJa01G31+suw2TaaabosOUV9dLvau05JLmLhc9O/ZD6NYZrMRDV0Q1hhT5WbJxUwE9iLgBGGxNVFZ/tIThj8wAb2D9TuTRStaS0PGsTIVZ+hRqtdKXoZ+eL6OjZOl+HE1Z9Ui+33mx5of4rt7DqrjaZdLk+QSu1zafsQVY5+TosIir82FO8nQVz8eydAFYQCkJZdMht6DiNNOQ7cXWNi9/yROLKkJ215m6EbyML1VoijdrzxvruDxI4vYuXU6fmwufIv1ABsmSk3H9cMIruPixq8/hE/88AmcsXECF5w2k9LQmVlNimofej9dLtmxGZSGrn6/ZS25FFkXzfhkxSJBWCMYXfm02Wqctfay9L+l5JJpbPWDvSo795z83uNZOi39N5l87HKJopTLJXvBiSLG40cXsXPbVPzcrA7iJ5d9fOHup3DDl+9PTWqac3Vy2ccZGyfwd3/8Upy1eTLlQzfDdI3LpY8B3T4n6Qw9bM7Qi1xI4kMXhLXFc87YgIu2z2LHlskml0svmnP5rSQX3QzMBI6jCw1MlV1snCx3GNA7W+DCBP6Uy6VFYdHTJ5fRCCKcuzUJ6ButgP79hw/juw8dSh3XyBZBpLpVGqufbVu0JQwiQj/boafGlrEtVuJJUa2hB61dLmJbFIQ1wq9efBpu+4NfxmTZxZKWISo9LP33Q9UzJW9f5rnYLx1G8FwHE2UnVV1ZRKftc812tstlsYXLxThs7IBuZ+gnlhsIwih1wTM/R7pwyGBr6JEVIF2nc7/9SrALtszFhllNDldj2yI1bWtjmnN5EtAFYW1R8ZxYEqj0sPTfBOu8LD0b0Bsho+Q6ha1qbZi54+ZcZv8T5WSyNzUpGkbYvf8kHtE9bUxA32kF9A1WQD++6DetBmRbGO0AWNWVopHVm9wdgMslPTb1+eOGY9kMveBWIbDGu1okoAvCACl7rvWzztB7YltU+8ibeIsLc8IksJdd6iig+6GeYKT20pAJWCYzNaX/JvAGEeNdX9mN93/jYQDAY4cXMVV2sW2mEu9jg3a8nFzycXLZhx9FKQ3dHCOMODWJaC4i9SBKNbvK9nL50d6j+NI9+1p+jm6wnSsmuMfriXoZ22KB5CJrigrCGqVsedN61ZzLzkrzrHFFkku15KYy6DxMwDe9aPKWc7vqL76PT//4STR0wEoy9KjJrbLcCONCpcePLOLcbVOxrxwApsseHNIZ+lKjqbFY0teF4VlLtpm7nZofgk0pfdwPPRnrZ+56Ev/ltj0tP3M3pDJ0PU574WvAcu5Yjp/UPqTboiCsTezCkqT0Pz+gv/1L9+OLdz8FQAW/onUpbW22peQSB3ZGySVMltN9U/afWI71fUPWipgto48ixqOHFvDEkcU4g58o2b1cwjig+2GERhjFge+xIws417IsAipL3TBRwpGFOpYaIfwwvbCFb02K2hm6uQsImZNJRgLcjG0xjBhHFxupgqfVEOTIQXGGriWX6ao6dwu1goBuMvRBSC5E9DEiOkREu63n3k1E+4noPv3vlaseiSCsA+wy97iwqGDS7rbdB/Cjx47ixFIDL//v38fXClYdsu2AeeX/SfZuNPRIaehWdWUYMa754N/hw7fvTb03nuiseql9GUw2atsmqyVbQw/iiU5TsRrqvib7jy/jrE0TTePdMFHCE0eTlgT2RcocP2JOaehGrrDX9zTdFvM0+CePtm950AnpDF2N07h9TC8X4/opuoiYC86gJkU/AeDqnOf/OzNfov/dtuqRCMI6oJKboasA8ODTJ2M5ItJl83U/woklH37IOL6Y3x7XD9pk6JyWXEwJul2M89jhBZxY8vHMyVrqvbbkAjTLQ+b1Rsix5FK1etQsWBl6EDL8QHWFDCOlzdtl/4YNEyU8eXQpfmzfRSSyUdrlYuv0tsvFcQj29dIE4J9b+18NaQcO45sPPoOfPnUCQHIeZtoEdHPHMhDJhZnvAHBs1UcSBCEtuRgNPWScXPbxG3/5A3z1pyoLX2wEYFbBzBTsFFWC2kE8bxsTc2K5IlTZrd2q9oH9JwEkLX8NJts0VsTsBK55v52hT2Qy9DigWxm6uTDYOrhhdqKEA9aFJbsKktm3HQBNY6tml0vWiaIz9GOdB/SP3vk4Dpxczn3N3ncYMf7kK7vx/m88BCC5WMWSS5sMfdiVom8lovu1JLOpaCMiup6I7iaiuw8fPryKwwnC2icluVg+9KVGgDBSgR1IFseoBWEc0IpKx+2y/lYZemA5YWLbopZcdu+fSx3XYF6ftvqzpF7PC+h6EtAPIyz7oSXXaA3dCrp5MoO5ABjMXYvZh/lM6YAOPb5k36bbYlpDV+/vVHI5ttjAf7r1Z7jpjsdyXw8y577mRziq76RMhj5RcuEQUp58G/MrG+ak6IcBPAvAJQAOAPhA0YbMfBMz72LmXdu2bVvh4QRhPMjN0C0nhwmKcUD3o1QWnEcrycUs3wYkFwQjuUyUXSzpVrW7izL0IB3Qsxq6PTbzGUyGXvNDMCfv9UNGI0hn6HktY+1mXUCyqpHZhxmHl5Ohh5bk4hKBMqX/ZoxPdii5mIvJ3z50KLdAKevAsecwjIZORJiqeE0Xy/h9w+6HzswHmTlk5gjAXwF4weqHIgijAxFdTUQPE9GjRHRDr/Zr2xbjJegihm0pBJLAWvPD9gG9heRix9/A0p89hzBRdrWsE+HBp1VAzwYdU0lqsuyshm7G1gg4vmAYqcEsbjFVTi4G/goy9FoqQ0/uNvI09OykqJuxLZrXigL60YU63vTJu+P5ChOgnzy6hMdyesdnNXT7bsJk6IC6qBVl6FGLi1u3rGgPRLTdevhqALuLthWEtQYRuQA+BOAVAC4C8FoiuqgX+66UmguLAitjbeiAPJ8K6CazztfQG2Fxhp6nH/uW5AIAPzswh8WGWphiTks+P3z0CBpBFEsqxRl6scvFLG5hmnXVgzBuT2ACYZ7M0BTQ/ebPF2UkF6M/B1GUnhTNaOgmGz6g+8hkuX//SXxnz0Hct09NbNrb/O2eQ03b2/uuB1Hq4lGxisimK17xpOggK0WJ6HMAfgTgAiLaR0RvBPBfiegBIrofwEsB/OGqRyIIo8MLADzKzI8xcwPAXwO4thc7Tmfoicslm6HbkovJ+opWJLJv+7M6uy03mNcaYYSSlwT0f/j5cQDArnM2Yb4W4PEji3jd/7oL3/7ZwbjwaKZthm4HdPW5zHvNeqrLcU+YqLsM3c/J0KP8DD2KkrsSh9AkuSS2R2Df8eYsva6PdUwvuF23A/pDzQHdPh9LmYBtO3imWgT0pFI09+WuaNsPnZlfm/P0R1d/aEEYWc4A8JT1eB+Ay7IbEdH1AK4HgB07dnS043LOpKgtQfix5KL++OtBGE9MdiK5ZCtF8yoZg5BR0pILAPxcOz4uOHUGtz98GI8fWQAAnFhuxMeeqRoveatJUY4/o0NJQDcZ+nJDT2iG3NKq1zwp2iwpqeZcybl03SRD9yL1s0t6UjRzDky2/MxcDTu3pQubzN3AMSO56HN73inT+Ienjsd3Nwbb9bOUaaNgSy4z1eKALpWigtBf8v6ymvSOlUz4p10uWkMPkzU/zf9G+lgFctjkAAAgAElEQVRutNfQW0ouOX1QTFAyGeS+48twCDhz8yQA4PEjKsAv1cMOMvRmyaXkOPAcJy51r3guXIfitVRTGnqObXHDRDn12NaljVQTZCdFqVlDTxa4sM5HxJjUF7K8Ox5zrGNLaQ398p2bUfMj7Dkwl9rePh/m4me6K2Yll2KXywAlF0FYh+wDcJb1+EwAT/dix8Uul3S3xMS2GKEWV2MW+dCLbYthzmt+RnLZd3wJm6cqcS9yk6EvNUIs+QEqnlO4/qldWOSHqgOisQuaRZwrJUctphEvQNHa5WIydBMYbZeL3cslt/Q/43LJNucKosiyVTafzzhDX8gG9C0AgHuePJ7a3r4DMgH7t/7JmXjDC8+Jxw9oyaXA5WJr/qtFArogNPMTAOcT0blEVAbw2wBu6cWO7YDuOIgn7YKM5GImRdUiESoQFPnQ7R4v2awzzLHs+SGjrEv/AZWhb50ux1n4EyZDbwRYboSYLLtxJt1U+p+RXMx2nkNWhq4Cusn227pctG1xy5TqwpiuFC2yLRaX/mc1dHMhy8vQzbGOZlwuOzZPYvuGKu79+YnU9rbLxUgul+/cgj/99YvTTcdaaOitzkW3SEAXhAzMHAB4K4BvAtgD4AvM/GAv9m3fhntamjAVlEASsGz7oFn/0y+YFG1pW8wpOjKZtAlsS40QW6bLsU5u+pQvNZTkMln24ky6qfTf0vcbQaIvu24SwBPJJVn5yIyllYZu2uraGnpoSS6u2xzQs6X/WdtiEHGq8ClLoqHXASQX0bLn4NIdm3BvJkO371jMpGg5x1BuAnqel92WiFaLBHRByIGZb2PmX2DmZzHz+3q1X1tDjyftOK+wKCnwOaH19GINPS0p2KQ0dNu26CUZOqCy4Q0TKkN/Wpe5LzXUhOxE2U1JGjZxWwLtcjHBzHMovrOoeA5KrpNa+ahVVjpVdvHPLz0TV114KoC0hp5k6FFKc44zdOak8jKn9L9jDT2ToZddB8/fsRH7Tyzj4FzSlsDet7mA2Xdhhumqaj9sWzCz+xANXRDWGPYfu+sSPIcQhIkvO+tyAYATeoKuUEMPWkgumW6AzKzb5yYaOoBUhm6uAUuNAEuNAJNl18qAMy6XhrFCqotSnKFbEku15KQepytFm4MYEeEDr3keXnS+0q1TvVysBS7cPMkltCdFk6zXZMaBLbm0yNCzkkvZc3DR9lkAwN5DC8l4OgzoprnZfN1vek1cLoKwRmnK0F1CGEXJ0mqZwiIgkVwKe7m0kFzCjORijlOyJBcA2DpdwWw1bRdcaoRYbISYKHWQoWuXS8kzGnra5WJPiqZ96MUhyLxma+jFzbkSyYXtSVFKjzuMGBPaF5+roevPM18L4IcR6pbksmVaSUDHl5LfjW3jNJ83T3IxHRftRbMNsQ9dMnRBWFukMnRHZ+hWL5dGLLkEcU+TE8smQ+++OVc6oCfadVZy2TxVRlW7UQz2pKgdMG1sS2UjjFBykgzdZPoVz4HnOtYizmipoRvMBGtuQM/0QzfBP7IXuNBuG3NMQGX4E6XiNT7tYx1fbMRBv+K62DSlfh9GX7fHU3KTC1YlpyWwqbTNc7qYYcikqCCsMezszdUBx+7lYtsWt+mMMJ4UXUFzrmxjKrOuZcl1UPEcmKRwy1QZRBQvRgGYSdEAk2UvDphF7XNNpWjJ0tANJkO3l7szgbKU40M3mH2lJ0WLMnT9GW0fOlH8+cx5iDipXM3V0C1556gV0Mueg02Tyh9/bNHO0NV+q16ynF9eht5SctFZfi8mRdtWigqC0DtStkVSmaW9zJpZ5X6hHmDbTAWPHFqIHS9FiwzbQTwry9gP/TCKl6sru6oT4YReV9TICTNVL54QXGqEqPtqUjSrof/VHY9hsuLGmnOgOw0aycUOtpWSA8+l1ILUZvKxZYauX6vnXLCypf92P/TI0qTNRGO8UHYUxbJX3gXSnoA9lgnorkOYrXo4vpQsNGJ+b5WSE7c+ztPQjSU0T3LJtgJeDRLQBWGAGNui66iAWnJJt55NMnRzW25se4Z2pf8Vz2lZ+u9bPWM8N+nVvdQIsXVaZZ9GR980WcJSI0A9iFI+9CBiHFmo48+/+TAuOn02pcMvNcLUpKih7DpwHSeVEZsg3UpDN/sydwGkHStRxGBOH8NesSjtcmnW0F2HUPacWB+3qfkRZqse5mqBytDDUK1Nqve/eaocT5ja+614LvywoX8uztAXcjP03jhcAJFcBGGgGInB/AGXXCfVB6URctw610guhuJJUfXeibLbWkMP0pILkDSQsjN0QBXSGB+6naGHEeNzd/0cjTDC8aVGqrWtHdDNBaDsOnD0XIGNkTZaZabmtZofwSHVUsAPE43cDoLJmqJRrssl1tB1QVLZdXLveGp+iNM3qnVOjy3UVRGWFaA3TZVTSwHaF1NDrm1RB/Qv37Mfb/rk3anXIuaeNOYCJKALwkAhovj2HVB//GZZNkBN2s2vIEMvuTpItejlEkSJ5GIuLBNlFxXPwZSeIDUZ+pmbJ7FYD9AIIkyWvDgg1/wQn77rSQBKkli2dPHFRpBcsHSEMoEu27PFSBt5vVwM5rV6EKoiLJcQWOfKLixKXDhISS7mehGlMnsHZc9BI2yWP2pBiFNnqyBKJBdbE98yVY4lKXU8Vhcba5uiwiIAuPPRI/jOnoOpuxVV9dqbUCwBXRAGTMUK6CXXUX1QLB+6sSw2B/RiDb3kquKdRtBCcrFdLpbksnW6Epep2xm6eetUJcnQHzm4gINzdZy7dQrztSBV0bpUD5smRSul5klSIJFcWmXoxjFT96OUIyivKMnNydBN4RaQ7h/juVrqysnQ676SmDZNlnFsqYF6EKFsVfdumiw3aejmYmPIy9CNF99gXwjNRaEXSEAXhAFjB3R16x+l+qyYnh9bM5JLtvT/S/fsw5UfuD0uFDJ6vI3tcvHDqElymSi72DyVdDfcNlPBbNVLyT2qUlRtbwL4zq1TAICDc7U4GKkMPa2h23MGNomG3j5Db+hWBZ7rILA8+7Zv28gv2dJ/c6EKOd3jRWXo+T70asnFhokSTi6rOxRbTjEauvG6G03e/hx5AZ2I4iwdAJb85EKYdeysBgnogjBg1CShztC95klR4xxpWlszE4AeOTSPvYcXMbfso+QSSjrgfeEnT+GBfWpJuWylaFZyectLz8O/f9kvxNtc/+Kd+Pzv/rO4hzmAlA/dXGzO2KR05iDiuMJ0qRGmSv+BRHIpZWSIjjJ06z1GhzeTovYxgER+yXZbNIGeOXHoeA7pO6P8SdFqySygHaCh1181bJ4qoxFESaMxvZyf+RxExRep3/uVZ+GfX3pmfK4MvXS5SEAXhAFTKblxdmkCi91nxejLM9USbPODr0v3DUaHPbrYSEku7/nqg/js3/8cQNblwnGWb4LlS35hG1767FPibTZOlnHh9tm4mhIAJiwNfV4HdDNxCACzE8nydF6soSdzBPZjQ6yht9COsy4Wz6GUxdO1An56TVH1nEOJhp7twlh2ncJuixXPxVRFuX8aQZjSxDdNGS96Q+83gudS7Boqu06qy6LN777kWXj5xao/jS25RJlWwKtBArogDJiym1RkmsBiL+BsstdqyYkz3ImSWtA5u4YloIKLkVxqvirXNwEz7XJJ3DTZjDnLVDmToetAvaD1/TOsgD5TSe4kmiQX7aLJBu5OXC5ZjdxznfSkqO1ysSWXXJeLpaFrySXXh+5HqJQcTJQ9LDZCNSlqZ+iT6YCu/PBO0x1JEWbB7KWMht6LKlFAArogDBzb5VLysrbFKPZdVz03thWayUp7YrSRCuhKRjAeaRMw0y4XbpJcipjIBHQvI7nkZehqv/mSS/OkaJj7vA1Rok2bDD2IEtuil8ngAZXthimXi3ne6mroOLkZehQxGmGEqudiskByiTP0JZOhpyUXewI1D3NeTd8XQP2OelElCkhAF4SB0zQpGqbXFDWZd6XkoOqlA7qt+5rtji8lksvRBdVnxFwUbL1ZTYqmJZciJm3JxdbQ9aTo9g3V+PUZq6lXOSO5mIDuZm2LJkNvc2GJJRyXtG2R4/YDTiaDB9Kl/8rlol6POO2OMf7/1JjiOyMXk7Hk0mxbBBB70f1Q6d/mfLbL0E3r3qzLRTR0QVijpDJ0UymqM+eIkVoYwiw0bIJmqsxfZ7mmoKfkObEUUMtILpXMnUB3kkvSy8Vo6DNVL16Iwlxs7P16sQ9d7ae0ApeLep++IBDFi4HYk5sGsnqf2y4XJ8fl4hiXSyZDj++MSg4my1ZAz8vQMxp6ds6gCBPQs5KLVIoKwhqlnPGh24EWUFlwSQeJZsklv/e5KiyiWCc2Tpk4oJfcVN/1biWX2JqoA3q1lNgd7ba7XpOGbh5nXS7te7mo/SUZv+cSgihKFQ6ltnWctD3RKv3njIZu/P825iJYLbmYLHtx6wM7SM9W1QRxWkOn+HzmFRXZTMQZeiK5RCK5CMLaZfNUGbM6QJc9B3VrUhRQ/T5MZmsmFU3QtIth6qmA7qQmHuNJUTbdAJ14mTizfSumMpKL0bMjRqzXb9K2SrtDo5Fc2mvo7Xu5AMmFwNMTj60Wx3CctJsllaFHSVdD1yFUPCe+w4nH5Cdl/BMl1XgsG9CJCJusatFEQ9culxVOivYqQ5fmXIIwYN51zUVxNmjK9e2e5ov1MJZaqp6RXJo19EYmoJesYJKXoatK0c4kl1SGXkqKg4KIY11/s17EeTZHcskWFjWV/vsRiNpn6CU7Q3fSbRJyM/Rst0VLQ2er77iSuoozdOPDP7nso5I5V6fNVvH0SbUMXVwp2qHkYq/jagij3qxWBEhAF4SBs8mqzCzpSVE7Q5+vB3EgbCW51DOSiy2jxJOinGjogdVtsZ3kYiZuXUo81p5DqAOolk1A1xm6JbmYi4oJ4K1cLp1Y9bKSSyOIUpObNqa3vLk2OoSkUtS6YMaVok0aemIXNT78k8t+U5A+Y+MEHjk0H+/XcxM3TjvJxXEI1ZKDJdvlEkUyKSoI40DJVVmlHVwWan4cCE2mPps7KZrO0O1gkmTo0PsxGXqyYlEriAiTJTeVqZugY7LMOEPPsS2219A7C2L2Ckiq9D+RXLK6s7qDsLotZipF4wuBm+9Dt+2i5q4kjLjpbuaMTRPYf2I51uXNxQZon6ED0Pq8XSnam8UtAMnQBWGomAUh7MUfFupBrJ23nBS1fi55Tirw1H3jckl04ZTLpYPufpMVN6Xt2j3UgSRDt22LpVhDz7hcmrotRh11GPQsTd7TATuv9B8wGXpi1XQditvSpnu5mKrafNtipeSkWh/kZeg1P8KxxYZyuTidu1wA6LYC6UrRNjdMHSMZuiAMEZNV23/gC7UgydBjH7oKmnY3xbp1EShZWSJg2xbV46p2uXQquQAqk8zL0I3kcuamSTgEnGJ1hWzW0PMf1/2wowzdtTN0h7RTp7lSFICeNI1S/dLjwqKMDz2vOZfJ0Cuem2p90BTQdR+b/SeWYx+61+GkKIC4rYBBfOiCMCaYAGD/gSsNPS25tM3QM5KLKVYKLQ3dNAHrZDISUJmkXWDkxZKLOs7VF5+Gb/3hS+IAZ8Zhb5v0Q0+6OwImQ+9AcmmyLXIqA7dxiDKl/3alaGLZjHu5ZHrjJD50N/aLA826uGl7sP/4ctzLvNPSf3UOPCz5tuQiAV0QxgITAO2AvlAPYqklkVyaNXR7QeOs5AKoiUcT3JSGHqGhW+0WNZCy2ThZiouHgGYN3XEI550ynTquHYABu5dL+r2NDjV08z6TBQdh0j4365zxXIpL/10nPY7I1tB1QG/qjWNPipaKJZezNk0CUBl6oqF3VikKKNfQUr0/7XNFQxeEIZIE9AAOqcDDnASGLdNlTJbdfJeLnaFb5eeGmp9MEFZLakLRD6Omqs0i3nvtc1LdHuOgbGWv5nkiNe6i9rnZi0E9iFIVpkXYDpvsAhfZDoVu/Hoix5hNsv50MyncCKP4GEamUt0Wk0CfDdKzEx6mKx72HV9GGKnVojp1uQCqUOvAyWRt0bCH3RYloAvCEDEZ7VIjxGTZi5tfmcz89ZefjSuefSqAZM1RQFU+NvvQ1b7MhaHmh5Zt0Y0ll3YOF8N5p0ynHscaeikd0NVi12qSMakUTWes5nOa9zbCqG0fF/t9brwEna2Fpz+HS8a2mKzRaVeKZjN0QBdqaRepnaFHXJyhExHO2DiBfceXEWgNvatJ0bKbmgSPRHIRhPHABJZ6EKUyXxMIJ8teStYwzbWMfm56rpQ8J3aumAWfa34YyxNKQ1fdBNsVFRVhAuhEJqDbnyN2ucQ+dFOUlNbQ7f11ckzXQY5tMb2t8aHblZe25GJXmJqLWt1aV9TW0CdaaOhAYl00GnqpK9uim/GhSy8XQRgL7ABgB0rj3zbEAV0HcpOdb9UOE9MPHUhcJ/XAllzUvmt+55JLlqxskh5fWnLI+tCzGrq9TSuS9rlObFssytA918rQKblbAdK2Rc9x4upPu1q0FoRx58TJFho6oCZG9x9fivXvuPTfbd0+F8jxoQ/S5UJEHyOiQ0S023puMxF9m4ge0f9v6sloBGGdYWfLdrCrZvpqZwO68UybBlklK+s8dVa1tq359qRootV3KrlkMVl3VkO3xxdXija5XJrf23WlqOMgDNP9zm1cIoSsXC6mUMe2LaYzdPW8LVvV/CjlyjGBPC+gn75xAnO1ACeX/VjfL9o2i+nkaBw2g5ZcPgHg6sxzNwD4LjOfD+C7+rEgCF2SCujl4gy9HE/iaS1dB6ItulrTdrmYDL3mR5ZtMekhslLJpUhDtz9HYS+XlWbo9qSoS/CjKNVkKzs+Y9V0swE94vh9SkNX40i3UghTn81YF/Mkl1Nn1Tk+uthYQaWoq6qDzSpV0QC7LTLzHQCOZZ6+FsAn9c+fBPCqnoxGENYZZS/5Q55MaejpoFkukFy2zegM3fKhbzMBXdsWidKTrytd7sxrEdDLmcw8W0iUp7935EM3gdkqLDIxOPt+ZWtUrzt5GnpoZehufoZetQKykV3ygrS5CwKQ7uXSoQ8dSIrJohHQ0E9l5gMAoP8/pc32giDkUCi5NGno6g/eTIrWMxl62U2yxFhD15OiLiVyzHIj7Cjo5NGRhp6xKZrPkSu5dHCnkM7Q9aRomJ+hOw5iycXsOs+2aHq5AOnirJofxr55AJisJC2Os5gM3YwjdvV0aFsEktqDXhYW9d22SETXA7geAHbs2NHvwwmr4Jwbvrai9z1x4zU9Hsn6ITUp2iJDd7XXO5uhn6aXgpsse7j49A245KyNuPiMDQASycV1KHbALPshNpfLWAlxll1uDlrl2J5o7Iqu3taLxw+kpaTuC4v0Ra0goHuOg2U/VJ85k6FzRkMvZ1xDgDqntufcBN68YqFtM1aGri2V9nloRTagR1Gzp36lrDSgHySi7cx8gIi2AzhUtCEz3wTgJgDYtWsXF20nCOuRTjP02OutZQOzgMWOzZP49Bsvw65zNqFacvF/3vJC7D+xHG8TZboBLtaDVHbZDa0z9LRt8VcvPhUOPS8uk1+p5JJqzqV/NncnzRl6UvqfnRTNulzyMnQ/syC0GWuec2W26qFaclDzo9SkaEeVovEiF8q6aBbJ6AUrlVxuAXCd/vk6AF/pyWgEYcgQ0b8gogeJKCKiXf0+XrloUjRn9XizGAaQZOhlz8GLzt+a0rWNDqwqRZX7w24xsHIfeueTojPVEn7z0jOb3lvx3FgG6SxDV/tzrKBp/OJ5zbki7VP3MgG9yYeemZMA0OTRn9KSS8lrHicRxTq6WsC62BGTJZuhD3RSlIg+B+BHAC4gon1E9EYANwJ4GRE9AuBl+rEgjAO7AfwmgDsGcbBCl0tOYDALSgNJ2X9eAEk852G8XuXpG1XwWagHq3a5tC4syt+3qQq1y+S7ac7lWR0N4ww9U2lqSv/thZ3NIaJMU684Q89ILnkX2KJy/lO17NKtbTFZVzRZhGSFv5Im2kouzPzagpeu7M0QBGF0YOY9ADpqXtUL7Da2acklPwuOA7q1/mWWipWhB3o1nItP3xD3QumkdW4erX3olPq/6XWrvazrkG472/mkqOs4qYldIKcfOqn2ufUgtCpUm33onpWh2wtFN0JOzQ+0crkAwDYtXblOsuh3p71cAGtSdARcLoKw7iGi64nobiK6+/Dhwyvahx0sKp4bZ5T5GboT90M32m/edp6rqiprQRivV1ktuXj29pn49ZXgtij9z0ouze+l+HWTaXdjW/Qcij/rog6ETc25dKVoI0wmN5NFohnZRaKB1hl67EMvCOh2hj6j5Rl7wewizELRC3XVoCsapOQiCOMGEX2HiHbn/Lu2m/0w803MvIuZd23btm1FY8m2no3bsBZ4vZMMPekMmEe15KLuRymP8/PO3Kj20w8N3Wsd0D03Cehxa9sO7hRcS0M3xzWTic0+dBXQ674lucQuF6QWxsjT0P0w43LRQbpSUM5/apyhEy7fuQWffdNluHD7bNvPdNqGKjZNlvDDvUcBqAnbXk2KSrdFYd3BzFcNewwGOwCaLoBZ+1yybaKhN1po6IByydSCMOVxft5ZG/GZu36+Yskl1tBzJJeK68Ch4olOz0kkmW40dNvlYiZ7F3VHyrzS/0Bn6KY1b7aXi0MqyBdp6Pa5mal6IGqu2jWYSdGSS3Acwi+dt7Xt51HbO7j6OafhlvuejhuoyZqigjAGmNaravX4pMFW1rYIpDV0E4iKbHIVz1VuEE66Ej7/LJWhr1RyySvft8fWarI1XqLNztC7mBR1rQx9sR7CoeZ5Dle7XOwM3c30cjHjiAu1Motu2xfI1+w6C8/aNp17RwIAp1gaerdc84un43N//xS+99ChkagUFYSxhIheTUT7APwzAF8jom/2+5gpJ0emMCe9ne1Db52hV0oO6n4UV4oCwM5t09gyVcbmyZUVFrXs5eJRSynnF06bxusv34HLdm7pLkO39PY4oDeC3Na7Zok6paGrbSnVyyW5WzHnrR6kJRf7orR1uoJfvfi0wrGdYmno3XL5zs3YMlXGrQ8cWFuVooKwlmDmmwHcPMhjllxdoGL1Y8m7zVdyjNLOYx96QRCt6gy9WnZTGfGtv/+i1LJy3WAWV84LPlc8+5SmDpE2Fc/Fn73qF9U4rEUr2pHO0NX2C/WgqRc6oCZAI2bU/bBppSTTyyWWfpwcH3omQ2/HWZsn8CsXbMMl+s6nGzzXwfN3bMTeQwtgHn6lqCAIPaLiOZiHmRRNCnCylDxCzTe9XMLUWpZZqiUHdR2g7AC8fcNE7vadcMFps7Fsk+WKZ5+qV1ZqTzcul8S2aE2K1sP8DF3bMpmbfejG5WIuJo5u0JXS0MOoqwnjiufiE294QcfbZ5mpljC3PBePvRdIQBeEIWNu89XKN+rnIg19bllNCGYtdlmqJZWhT5bdnmV/r7tsB1532er7MXWjobuWPGPuABbrQe57XdMvHRxfEB0nq6En77PnJJiVVLPSxmUrYbri4eSynxrnahENXRCGTBzQXWWnI8qXUqbKHhYbSUAvcl8AOqAHYU8XT+gVK6kUdR0n/ryLjaKArtws9VSlaBLQs4sxlz0nztDDiFOLXA+C6aoXe+plTVFBGBPsKsuSq4pe8ipVZydKmNMZXb1thu7oStHRC+hx1t1J+1xrTVGToUecHwBd3Q/dLixyrV4u2SZY9iSzsYGudDWnlTBdSQQScbkIwpiQrPKjJJeiYqENEyWcXPaVPNAmQze2xV6uV9krVpuhA/kB0HMoqaDV22b7odvFTGXXibtWtptk7gfGKw+I5CIIY4PJJktOkqHnsWGiBD9k1Pyo4ww94t55nHtFNxq6PYGq7lzS+7Cxg2J2sWrO+NAB5VK59f4D+MJPnhqBDL03+1y3k6IrXcxBEHpNoqGrDL2okGV2Qv25nlz2UQ+iwkweUBl6PVAZeq+yv17RjcvFtWyLRCqoK4tnfoZuMK0Tkl4uaLpb+dDrLsWbP3Mv3nHzA/jG216s3jdIDd0O6D06rmTogjBkspOirTJ0QAX0do4M43KJot7ps72im14uJSedaZuLXd5nsoO1Ccxx+1xmBFGUCvpbpiv4teduRxAxTiw11PFyep/3i35o6Os2QxeEUSFubOU4uPLCU3B4vp67nR3Q637rtUGnyi78kFEPQsxUV1ZI1C/cLjR0z03LM2pi1C+YFLUzdKOhq6X7jMsl+z5zgZirqcnmvNWJ+sW0paEPrB+6IAj9pWxK/13Cv7rs7MLtTECf0xm6neFlMZ0C52sBNq6w1L9fJBp655WiSafHdMZuk5JcvPQEap4PHUj60hh//6B96IZe1QqI5CIIQyZZYLn1H3U6Q8/vyGiYKieZ51p2uezcOo3n79iIC05TvdxjySVvUjTjMbefz9PQgSSgmwKflXaiXAnpDF0kF0EYC2zbYitmq2kNvdWkqMnQ52pBz7K/XtGNy2XTVBk3/94L48dmsjPvYmBPlNrnxnG0yyXkppYB1UxAH2SGPlNJpDApLBKEMSEp/W/9R21Ww5mr+W0bSU1XVKBqBFHP9Nle4bmdZ+hZ4pWI2mjozRm6rhTNnAuz5Jwp2BqkD71a6q6VcCeM2K9aENYf7ZZvM7h6qTNlWwxbBp/Jcu9v53uF6xTr4O2otsjQbadIJRPQI4Z2ueRn6PGk6AAzdCKKdXRxuawhxPMutMKeFG3H7EQJxxYbOLrQwJbp4snOqVRAH628LdbQV6BXV73ii0Fxhq5dLjktA4Y5KQokDbqkUlQQxoSyZVtsx4aJEnbvP4kgYuzcNl243VQl0ZAHOM/XEd24XLK0mhQt1tBJ2xajpsw+m6G3u0vqNab8X3q5CMKYYBcWtWN2wsPew4sAgJ3bpgq3m6r0vk9Ir+jG5ZIlsS02hy6nQHKJbYthscsl8aEPNiSa31MnRVadIAFdEIZMNwHdXm3oWVuLM/TJsp2hj+Fd9egAAAtcSURBVFZAX81EYCsN3dbHbemELNti9hybBa+H4XIB0HMNXQK6IAyZXzxjA15wzuaOJRcA2DJVxobJ4grQUZ4UjZeBW4mGnunRYpOqFLUzdG1bVD709Dk2251cGk6Gbrzo4kMXhDHhqotOxVUXdbZ8mwnoreQWQAWIiZKLZT8cuYCeuFxWoKF7xRbPdrbFvEpRIrVW6XxdTYoOstsiAMzoDF0qRQVhHWKKi3a2kFsMZmJ01AL6qnzorSZFc9rnAoltsag3/ETJBXPz+wZBLLmIy0UQ1h9GZmmXoQOJ7LKWK0WzVDqwLWZXfHKc/G6LhgmrXfEgS/+B3ksuEtAFYQ1hJJdzt7YP6FM9zv56xepcLi0Ki/Rz2YlN43Ip6g1v9ll285f+6ye9ztDXvIYuRTvCeuK5Z27Ec86YxaVnb2q7rWnQNWoBvRcul1al/9keN600dHufg3a4AL33oa/5gC4I64lzt07h1n/3yx1tOznyGfpKCouKJ0U9S3KxcRwCMxDm+NCBxLo4aLkFQNyrfiVVs3mI5CIIY0qcoY+chr6KXi5ecYbuFAV00otEc1GGrrYfRob+0gtOwZ/++kW44NSZnuxPMnRBGFOMhj6ylaKr8KG3ytCzgdmxFrjIs0qaSdFBl/0D6u7gDS88t2f7kwxdEMaUUc3QnVVp6MXZvXHzNGfoyaToqGnovWZVGToRPQFgHkAIIGDmXb0YlCAIqyfR0Ic8kAy9cLnkXaRMxp+dFHWdpB96kQ8dGLwHvR/0QnJ5KTMf6cF+BEHoIYklbrQC1epcLjpDz5FriiUXwA85tU16n+OToa/9TyAIQi6TsW1xyAPJcN4p0zhz0wQ2T3W/eLXJvvMCc6Hk4hAaYQQg/0JgXC7jkKGv9hMwgG8R0T1EdH0vBiQIQm+YGtFK0ct3bsGdb78i1UCsUyomQ8+TXPSdiNnG4BChEUSF76sOcVK016xWcnkhMz9NRKcA+DYRPcTMd9gb6EB/PQDs2LFjlYcTBKFTJke0l8tqSBa4aA6+JvvOZtouEeYbqpviRNltet8wbYu9ZlWfgJmf1v8fAnAzgBfkbHMTM+9i5l3btm1bzeEEQeiCUS39Xw2TJRcbJkrYNlNpes2l/ElRImCxHgJILgg2E2Okoa84QyeiKQAOM8/rn18O4L09G5kgCKvCSC7jFNA918Ht/+FX4pJ5m8JeLg5hQbfHnczJ0MXlojgVwM26mY0H4LPM/I2ejEoQhgQR/TmAXwfQALAXwBuY+cRwR7UyJkfUh75aNhVMphaW/hNhsVVAL49Phr7iT8DMjzHz8/S/i5n5fb0cmCAMiW8DeA4zPxfAPwL4j0Mez4qZ6XFr1lEnLv3PToo6hCBStsWJUnMOaySaYfRy6TVr/5IkCD2Emb/FzIF++GMAZw5zPKthx+ZJvPOVF+LKCztbDWmtE/vQ3Wy3xeTnvEnRccrQpZeLIBTzOwA+X/TiqDu4iAj/74t3DnsYA6PsOdg4WcLpG6up523JqZWGLrZFQViDENF3AJyW89I7mfkrept3AggAfKZoP8x8E4CbAGDXrl3ch6EKXVByHdz59itSKxABSC1akX3Nfk4ydEHAyhYZeeLGa/owks5g5qtavU5E1wH4NQBXMrME6jWEaXdgYyfeeRm68aFXJEMXhPGCiK4G8HYAL2HmpWGPR1g9TkpyaQ5541QpuvY/gSD0lr8EMANV+XwfEX1k2AMSVofdDz5raQRkUlQQxhZmPm/YYxB6i8nQJ0pu7mIfGydKeNF5W3HJWRsHPbSeIwFdEISxxtjL8/RzQFWffvpNlw1wRP1j7d9jCIIgtCDO0AsC+jghAV0QhLGGLMll3JGALgjCWGPMK0WSyzghAV0QhLFmPUkuMikqDIWVFCMBwy1IEtYmxtmykhWS1hqSoQuCMNYYp6Jo6IIgCGscdx1JLhLQBUEYa4zLRSZFBUEQ1jhmgQ/J0AVBENY4RkOfzFmtaNyQgC4IwljjxBn6+Ie78f+EgiCsaxIfumTogiAIaxrjcpkU26IgCMLaxmnTbXGckIAuCMJYYzT0qgR0QRCEtY0jkosgCMJ44EovF0EQhPHArBEthUWCIAhrHFdK/wVBEMaDuPR/HWjo4y8qCYKwrnnZRaei5ofYOFka9lD6zsgE9JUueCAIgtCKs7dM4a1XnD/sYQwEkVwEQRDGBAnogiAIY4IEdEEQhDFBArogCMKYIAFdEARhTFhVQCeiq4noYSJ6lIhu6NWgBEEQhO5ZcUAnIhfAhwC8AsBFAF5LRBf1amCCIAhCd6wmQ38BgEeZ+TFmbgD4awDX9mZYgiAIQresprDoDABPWY/3AbgsuxERXQ/gev1wgYgeXsUxO2UrgCMDOM6oHHfdHJve3/K4Zw9iDHncc889R4joyZyXhvl7ySJjyWctjKWj7/ZqAjrlPMdNTzDfBOCmVRyna4jobmbeNchjDvO46/XYw/zMWZh5W97zozRGGUs+4zSW1Ugu+wCcZT0+E8DTq9ifIAiCsApWE9B/AuB8IjqXiMoAfhvALb0ZliAIgtAtK5ZcmDkgorcC+CYAF8DHmPnBno1sdQxU4hmB467XYw/zM3fKKI1RxpLP2IyFmJtkb0EQBGENIpWigiAIY4IEdEEQhDFhLAM6Ef05ET1ERPcT0c1EtHGAx/4XRPQgEUVENBAr1LBaMBDRx4joEBHtHtQx9XHPIqLvEdEefa7/YJDH75RhtsYoOkdE9G4i2k9E9+l/rxzQeJ4gogf0Me/Wz20mom8T0SP6/00DGMcF1me/j4jmiOhtgzoveX8zReeBFB/U35/7iejStgdg5rH7B+DlADz98/sBvH+Ax74QwAUAbgewawDHcwHsBbATQBnATwFcNKDP+mIAlwLYPeDf73YAl+qfZwD846A+81r4vbQ6RwDeDeA/DOF8PAFga+a5/wrgBv3zDYP8O7V+R89AFe0M5Lzk/c0UnQcArwTwdaian8sB3NVu/2OZoTPzt5g50A9/DOWRH9Sx9zDzIKphDUNrwcDMdwA4NohjZY57gJnv1T/PA9gDVbk8Sgy1NcYaOUfXAvik/vmTAF414ONfCWAvM+dV+PaFgr+ZovNwLYD/zYofA9hIRNtb7X8sA3qG34G6yo0reS0YRu0Pt28Q0TkAng/gruGOpImR+b3knKO36lv4jw1C5tAwgG8R0T26HQgAnMrMBwB1AQJwyoDGYvhtAJ+zHg/jvADF56Hr79CaDehE9B0i2p3z71prm3cCCAB8ZtDHHiAdtWAYR4hoGsCXAbyNmeeGPZ4MI/F7yTlHHwbwLACXADgA4AMDGsoLmflSqO6sbyGiFw/ouLnoYsjfAPBF/dSwzksruv4OraaXy1Bh5qtavU5E1wH4NQBXshakBnXsAbMuWzAQUQkqUH2Gmf9m2OPJYei/l7xzxMwHrdf/CsCtgxgLMz+t/z9ERDdDSVIHiWg7Mx/QUsKhQYxF8woA95rzMazzoik6D11/h9Zsht4KIroawNsB/AYzLw17PH1m3bVgICIC8FEAe5j5L4Y9ngKG+nspOkcZDfbVAPruUCKiKSKaMT9DmRZ2Q52P6/Rm1wH4Sr/HYvFaWHLLMM6LRdF5uAXAv9Ful8sBnDTSTCGDnFUe1D8Aj0JpT/fpfx8Z4LFfDXVlrQM4COCbAzjmK6FcDHsBvHOAn/VzULenvv7MbxzQcV8Edet5v/U7fuUgv2Oj/HtpdY4AfArAA/r5WwBsH8BYdkK5fH4K4EFzLgBsAfBdAI/o/zcP6NxMAjgKYIP13EDOS97fTNF5gJJcPqS/Pw+gA9eclP4LgiCMCWMpuQiCIKxHJKALgiCMCRLQBUEQxgQJ6IIgCGOCBHRBEIQxQQK6IAjCmCABXRAEYUz4v5INT87xX2DMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = np.random.randn(100)  # 随机生成一组数据, 符合标准正态分布\n",
    "plt.figure()\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.hist(y)\n",
    "plt.title(\"hist graph\")\n",
    "\n",
    "x = range(len(y))  # 生成x轴数据，从0开始的递增序列作为x\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(x, y)\n",
    "plt.title(\"line graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 总结&课后任务\n",
    "### 总结\n",
    "<img src=\"./material/第一章总结.png\" width=\"500px\" height=\"500px\"/>\n",
    "\n",
    "### 课后任务\n",
    "* 复习本节课内容\n",
    "* 把鸢尾花分类的代码自己分析复写\n",
    "* 预习下节课内容，提前学习常用第三方库"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
